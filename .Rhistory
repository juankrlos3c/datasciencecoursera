library(datasets)
data(iris)
?iris
Sepal.Length
iris
mean(iris[,"sepal.length"])
mean(iris[,"sepal.length"],na.rm=TRUE)
mean(iris[,"sepal"],na.rm=TRUE)
mean(iris[,"sepal"])
da <- iris
mean(da[,"sepal"], )
126.5779
library(datasets)
data(mtcars)
tapply(mtcars$cyl, mtcars$mpg, mean)
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
with(mtcars, tapply(mpg, cyl, mean))
sapply(split(mtcars$mpg, mtcars$cyl), mean)
library(datasets)
data(iris)
mean(iris[,1])
iris
mean(iris[,1])
mean(iris[,1], 5="virginica")
mean(iris[,1], 5=="virginica")
mean(iris[,0])
mean(iris[,1])
mean(iris[,1], 5=="virginica")
mean(iris[,1], trim.5=="virginica")
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
str()
str(str)
str(lm)
str(apply)
x<-rnorm(100,2,4)
rnorm(10,20,2)
rnorm(10,20,3)
rnorm(10,20,4)
rnorm?
1
?rnorm
set.seed(1)
rpois(5, 2)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
?rpois
?ppois
?rpois
?qpois
?dpois
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
x
y
e
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
system.time
system.time()
set.seed(1)
rpois(5, 2)
str(system.time())
?system.time()
system.time(3)
system.time(100)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
download.file(https:/d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
fileUrl1 <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl1,destfile="./housing.csv",mode="wb")
housing = read.csv("housing.csv")
housing$FES[1:100]
housing
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl1,destfile="./housing.csv",mode="wb")
housing$FES[1000000]
housing
list.files(".")
housing <- read.csv("housing.csv")
head(housing)
length(idaho_housing$VAL[!is.na(idaho_housing$VAL) & idaho_housing$VAL==24])
length(housing$VAL[!is.na(housing$VAL) & housing$VAL==24])
library(xlsx)
library(xlsx)
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl1,destfile="./housing.csv",mode="wb")
library(xml)
library(data.table)
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
head(dat)
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23,
header=TRUE)
head(dat)
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="getdata_data_DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23,
dat <- read.xlsx(file="gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
dat <- read.xlsx(file="gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="getdata_data_DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
install.packages("xlsx")
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="getdata_data_DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
library(xlsx)
install.packages("rJava")
library(xlsx)
install.packages("rJava")
rowIndex <- 18:23
colIndx <- 7:15
dat <- read.xlsx(file="getdata_data_DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
library(xlsx)
library(rJava)
dat <- read.xlsx(file="getdata_data_DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
library(xlsx)
install.packages(rJava)
install.packages("rJava")
setwd("C:\Users\JuanCarlos\AppData\Local\Temp\RtmpolxV7Y\downloaded_packages")
setwd("C:/Users/JuanCarlos/AppDataLocal\Temp\RtmpolxV7Y\downloaded_packages")
setwd("C:/Users/JuanCarlos/AppDataLocal/Temp/RtmpolxV7Y/downloaded_packages")
getwd()
install.packages("rJava", lib="C:/Users/JuanCarlos/Documents")
library(xlsx)
install.packages("xlsx", lib="C:/Users/JuanCarlos/Documents")
library(xlsx)
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
download.file(fileUrl,destfile="restaurants.csv",method="curl")
dir()
download.file(fileUrl,method="curl")
download.file(fileUrl,destfile="restaurants.csv",method="curl")
if(!file.exists("./data")){dir.create("./data")}
dir()
dir(data)
dir(2data")
dir("data")
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
head(restData)
head(restData)
head(restData,n=3)
tail(restData,n=3)
tail(restData,n=3)
tail(restData,n=1)
resume(restData)
summary(restData)
str(restData)
restData
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs(0.5,0.75,0.9))
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$ZipCode > 0)
colSum(is.na(restData))
colSums(is.na(restData))
colSums(is.na(restData))
all(is.na(restData)==0)
all(is.na(restData)==1)
table(restData$ZipCode %in% c("21212"))
table(restData$ZipCode %in% c("21212"))
restData[restData$ZipCode %in% c("21212","21213"),]
restData[restData$ZipCode %in% c("21212","21213"),]
restData[restData$zipCode %in% c("21212","21213"),]
table(restData$zipCode %in% c("21212"))
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
s1 <- seq(1:10,by=2)
s1 <- seq(1,10,by=2)
s1
s1 <- seq(1,10,by=1)
s1
s1 <- seq(1,10,by=3)
s1
s1 <- seq(1,10,by=2)
s1 <- seq(1,10,by=2)
s1
s1 <- seq(1,10,length=2)
s1
s1 <- seq(1,10,length=4)
s1
s1 <- seq(1,10,length=3)
s1
s1 <- seq(1,10,length=2)
s1
s1 <- seq(1,10,length=5)
s1
s1 <- seq(1,10,length=10)
s1
x <- c("1,3,8,25,100")
seq <-(along = x)
seq(along = x)
x
seq(along = x)
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
reviews = read.csv("./data/reviews-apr29.csv"); solutions <- read.csv("./data/solutions.csv")
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
mergedData <- merge(reviews,solutions,by.x=solution_id,by.y="id",all = TRUE)
mergedData = merge(reviews,solutions,by.x="solution_id",by.y="id",all=TRUE)
head(mergedData)
intersect(names(solutions),names(reviews))
mergedData2 = merge(reviews,solutions,all=TRUE)
head(mergedData2)
hid = read.csv("hid.csv")
hid = read.csv("data/hid.csv")
str(hid)
agricultureLogical = (with(hid, ACR==3 & AGS==6))
str(agricultureLogical)
which(agricultureLogical)
install.packages("jpeg")
library(jpeg)
library(jpeg)
pic = readJPEG("./data/getdatajeff.jpg", native = "TRUE")
pic = readJPEG("./data/getdatajeff.jpg", native = "TRUE")
head(pic)
summary(pic)
str(pic)
quantile(pic, probs = c(30, 50, 80)/100)
gdp = read.csv("./data/gdp.csv",skip=1)
edu = read.csv("./data/education.csv")
labels(gdp)
labels(edu)
gdp
str(gdp[100,1])
str(edu)
table(gdp$X, gdp$Gross.domestic.product.2012)
table(gdp$X, gdp$Gross.domestic.product.2012)
str(gdp[100,1])
str(edu)
table(gdp$X, gdp$Gross.domestic.product.2012)
names(gdp)
names(edu)
gdp = rename(gdp, c("CountryCode"="CountryCode1"))
mergedData = merge(gdp, edu)
str(mergedData)
attributes(mergedData$Income.Group)
levels(gdp$Rank)
result = subset(mergedData, Income.Group == "Lower middle income")
str(result)
table(result)
as.numeric(mergedData$Rank)
result$Rank
q()
# Getting and Cleaning Data Course Project
## You should create one R script called run_analysis.R that does the following.
#1.Merges the training and the test sets to create one data set.
#2.Extracts only the measurements on the mean and standard deviation for each measurement.
#3.Uses descriptive activity names to name the activities in the data set
#4.Appropriately labels the data set with descriptive variable names.
#5.Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd('C:/Users/dsbmac/Documents/Professional Development/Getting and Cleaning Data/Project')
# load libraries
library(reshape)
library(plyr)
# give them headings, and turn the numeric activities into something easier to read
xTr = read.table("./train/X_train.txt")
yTr = read.table("./train/y_train.txt")
subTr = read.table("./train/subject_train.txt")
# test set
xTest = read.table("./test/X_test.txt")
yTest = read.table("./test/y_test.txt")
subTest = read.table("./test/subject_test.txt")
## Format x datasets (xTr and xTest)
# format variable names
# load headings from file
featuresdf = read.table("./features.txt")
headings = featuresdf$V2
# transfer headings to data set
colnames(xTr) = headings
colnames(xTest) = headings
### format y dataset (yTest and yTr)
# change V1 variable to something descriptive "activity"
yTest <- rename(yTest, c(V1="activity"))
yTr <- rename(yTr, c(V1="activity"))
# change data values in yTest according to activity_labels.txt file
# there are 6 activities
activitydf  = read.table("./activity_labels.txt")
# convert variable names to lowercase
activityLabels = tolower(levels(activitydf$V2))
# convert $activity to factor and add descriptive labels
yTr$activity = factor(
yTr$activity,
labels = activityLabels
)
yTest$activity = factor(
yTest$activity,
labels = activityLabels
)
### Format subject variables (subject_train subject_test)
# change subject variable name to be descriptive
subTr <- rename(subTr, c(V1="subjectid"))
subTest <- rename(subTest, c(V1="subjectid"))
### Merge the training and the test sets to create one data set.
# combine (x,y,subject) for the training and test sets
train = cbind(xTr, subTr, yTr)
test = cbind(xTest, subTest, yTest)
# combine train and test set
fullData = rbind(train, test)
### Data Extraction:
# Extract only the measurements on the mean and standard deviation for each measurement.
# keep the activity column as well
pattern = "mean|std|subjectid|activity"
tidyData = fullData[,grep(pattern , names(fullData), value=TRUE)]
# tidy up variable names
# Don't use underscores ( _ ) or hyphens ( - ) in identifiers
# remove parentheses, dash, commas
cleanNames = gsub("\\(|\\)|-|,", "", names(tidyData))
names(tidyData) <- tolower(cleanNames)
# summarize data
result = ddply(tidyData, .(activity, subjectid), numcolwise(mean))
# write file to output
write.table(result, file="data.txt", sep = "\t", append=F)
# Getting and Cleaning Data Course Project
## You should create one R script called run_analysis.R that does the following.
#1.Merges the training and the test sets to create one data set.
#2.Extracts only the measurements on the mean and standard deviation for each measurement.
#3.Uses descriptive activity names to name the activities in the data set
#4.Appropriately labels the data set with descriptive variable names.
#5.Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd('C:/Users/JuanCarlos/Documents/data/getdata_projectfiles_UCI HAR Dataset/UCI HAR Dataset')
# load libraries
library(reshape)
library(plyr)
# give them headings, and turn the numeric activities into something easier to read
xTr = read.table("./train/X_train.txt")
yTr = read.table("./train/y_train.txt")
subTr = read.table("./train/subject_train.txt")
# test set
xTest = read.table("./test/X_test.txt")
yTest = read.table("./test/y_test.txt")
subTest = read.table("./test/subject_test.txt")
## Format x datasets (xTr and xTest)
# format variable names
# load headings from file
featuresdf = read.table("./features.txt")
headings = featuresdf$V2
# transfer headings to data set
colnames(xTr) = headings
colnames(xTest) = headings
### format y dataset (yTest and yTr)
# change V1 variable to something descriptive "activity"
yTest <- rename(yTest, c(V1="activity"))
yTr <- rename(yTr, c(V1="activity"))
# change data values in yTest according to activity_labels.txt file
# there are 6 activities
activitydf  = read.table("./activity_labels.txt")
# convert variable names to lowercase
activityLabels = tolower(levels(activitydf$V2))
# convert $activity to factor and add descriptive labels
yTr$activity = factor(
yTr$activity,
labels = activityLabels
)
yTest$activity = factor(
yTest$activity,
labels = activityLabels
)
### Format subject variables (subject_train subject_test)
# change subject variable name to be descriptive
subTr <- rename(subTr, c(V1="subjectid"))
subTest <- rename(subTest, c(V1="subjectid"))
### Merge the training and the test sets to create one data set.
# combine (x,y,subject) for the training and test sets
train = cbind(xTr, subTr, yTr)
test = cbind(xTest, subTest, yTest)
# combine train and test set
fullData = rbind(train, test)
### Data Extraction:
# Extract only the measurements on the mean and standard deviation for each measurement.
# keep the activity column as well
pattern = "mean|std|subjectid|activity"
tidyData = fullData[,grep(pattern , names(fullData), value=TRUE)]
# tidy up variable names
# Don't use underscores ( _ ) or hyphens ( - ) in identifiers
# remove parentheses, dash, commas
cleanNames = gsub("\\(|\\)|-|,", "", names(tidyData))
names(tidyData) <- tolower(cleanNames)
# summarize data
result = ddply(tidyData, .(activity, subjectid), numcolwise(mean))
# write file to output
write.table(result, file="data.txt", sep = "\t", append=F)
